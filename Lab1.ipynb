{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Bhavna Panwar\n",
    "## Student ID- 100802837\n",
    "## Lab Evaluation1 - Object detection model for CIFAR-10 dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description:\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n",
    "\n",
    "Here are the classes in the dataset:\n",
    "•\tAirplane\n",
    "•\tAutomobile\n",
    "•\tBird\n",
    "•\tCat\n",
    "•\tDeer\n",
    "•\tDog\n",
    "•\tFrog\n",
    "•\tHorse\n",
    "•\tShip\n",
    "•\tTruck\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# reshape dataset to have a single channel\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 32, 32, 3))\n",
    "\ttestX = testX.reshape((testX.shape[0], 32, 32, 3))\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform')) \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\tmodel.fit(trainX, trainY, epochs=10, batch_size=32, verbose=1)\n",
    "\t# save model\n",
    "\tmodel.save('final_model.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 190s 4ms/step - loss: 1.6621 - accuracy: 0.3989\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 165s 3ms/step - loss: 1.2394 - accuracy: 0.5602\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 174s 3ms/step - loss: 1.0402 - accuracy: 0.6345\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 167s 3ms/step - loss: 0.9098 - accuracy: 0.6812\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.8005 - accuracy: 0.7195\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 141s 3ms/step - loss: 0.7174 - accuracy: 0.7504\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 142s 3ms/step - loss: 0.6438 - accuracy: 0.7767\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 146s 3ms/step - loss: 0.5727 - accuracy: 0.8010\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 197s 4ms/step - loss: 0.5149 - accuracy: 0.8201\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.4502 - accuracy: 0.8416\n"
     ]
    }
   ],
   "source": [
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 72.180\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on test dataset\n",
    "trainX, trainY, testX, testY = load_dataset()\n",
    "trainX, testX = prep_pixels(trainX, testX)\n",
    "model=load_model('final_model.h5')\n",
    "_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "print('> %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
